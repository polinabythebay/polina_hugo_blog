
<!DOCTYPE html>


<html class="no-js" lang="en">
<head>
<meta charset="utf-8">
<title>Diving into HDFS - Polina Soshnin</title>
<meta name="author" content="Julia Evans">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="description" content="Diving into HDFS">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="canonical" href="https://jvns.ca/blog/2014/05/15/diving-into-hdfs/">
<link href="/favicon.ico" rel="icon">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/atom.xml" rel="alternate" title="Julia Evans" type="application/atom+xml">
 
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='https://fonts.googleapis.com/css?family=Montserrat:700,400' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Alegreya:400,900,700' rel='stylesheet' type='text/css'>
</head>
<body>
<div id="wrap">
<header role="banner">
<hgroup>
<h1><a href="/">Polina Soshnin</a></h1>
</hgroup>
<ul class="header-links">
<span><li><a href="/about">About</a></li>
<li><a href="/projects">Projects</a></li></span>
    <li><a href="https://github.com/polinadotio">Github</a></li></span>
    <li><a href="https://www.linkedin.com/in/polinasoshnin">LinkedIn</a></li></span>
</ul>
</header>
<nav role="navigation" class="header-nav"><ul class="main-navigation">
<li><a href="/categories/favorite/">Favorites</a></li>
<li><a href="/zines">Zines</a></li>
</ul>
</nav>
<div id="main">
<div id="content">

<div>
<article class="hentry" role="article">
<header>
<h1 class="entry-title">Diving into HDFS</h1>

<div class="post-tags">
  
  •
  
    <a class="post-tag" href="/categories/strace">strace</a> 	•
  
  
</div>
<p class="meta">
<time datetime="2014-05-15T12:40:39" pubdate data-updated="true"></time>
</p>
</header>
<div class="entry-content">
     <p>Yesterday I wanted to start learning about how HDFS (the Hadoop
Distributed File System) works internally. I knew that</p>

<ul>
<li>It&rsquo;s distributed, so one file may be stored across many different
machines</li>
<li>There&rsquo;s a <em>namenode</em>, which keeps track of where all the files are
stored</li>
<li>There are <em>data nodes</em>, which contain the actual file data</li>
</ul>

<p>But I wasn&rsquo;t quite sure how to get started! I knew how to navigate the
filesystem from the command line (<code>hadoop fs -ls /</code>, and friends), but
not how to figure out how it works internally.</p>

<p></p>

<p><a href="http://twitter.com/colinmarc">Colin Marc</a> pointed me to this great
library called <a href="https://github.com/spotify/snakebite">snakebite</a> which
is a Python HDFS client. In particular he pointed me to the part of
the code that
<a href="https://github.com/spotify/snakebite/blob/master/snakebite/client.py#L966-L1033">reads file contents from HDFS</a>.
We&rsquo;re going to tear it apart a bit and see what exactly it does!</p>

<h3 id="getting-started-elastic-mapreduce">Getting started: Elastic MapReduce!</h3>

<p>I didn&rsquo;t want to set up a Hadoop cluster by hand, and I had some AWS
credit that I&rsquo;d gotten for free, so I set up a small Amazon Elastic
MapReduce cluster. I worked on this with with
<a href="https://twitter.com/ptn777">Pablo Torres</a> and
<a href="https://twitter.com/SashaLaundy">Sasha Laundy</a> and we spent much of
the morning fighting with it and trying to figure out protocol
versions and why it wasn&rsquo;t working with Snakebite.</p>

<p>What ended up working was choosing AMI version &ldquo;3.0.4 (hadoop 2.2.0)&rdquo;.
This is CDH5 and Hadoop protocol version 9. Hadooop versions are
<em>confusing</em>. We installed that and Snakebite version 2.4.1 and that
almost worked.</p>

<p><strong>Important things</strong>:</p>

<ul>
<li>We needed to look at <code>/home/hadoop/conf/core-site.xml</code> to find the
namenode IP and port (in <code>fs.default.name</code></li>
<li>We needed to edit
<a href="https://github.com/spotify/snakebite/blob/25418007e93f99f6dc6807ca44d25287217e783f/snakebite/config.py">snakebite/config.py</a>
to say &lsquo;fs.default.name&rsquo; instead of &lsquo;fs.defaultFS&rsquo;. Who knows. It
worked.</li>
</ul>

<p>Once we did this, we could run <code>snakebite ls /</code> successfully! Time to
move on to breaking things!</p>

<h3 id="putting-data-into-our-cluster">Putting data into our cluster</h3>

<p>I copied some Wikipedia data from one of Amazon&rsquo;s public datasets like
this;</p>

<p><code>hadoop distcp
s3://datasets.elasticmapreduce/wikipediaxml/part-116.xml /wikipedia</code></p>

<p>This creates a file in HDFS called <code>/wikipedia</code>. You can see more
datasets that are easy to copy into HDFS from Amazon at
<a href="https://s3.amazonaws.com/datasets.elasticmapreduce/">https://s3.amazonaws.com/datasets.elasticmapreduce/</a>.</p>

<h3 id="getting-a-block-from-our-file">Getting a block from our file!</h3>

<p>Now that we have a Hadoop cluster, some data in HDFS, and a tool to
look at it with (snakebite), we can really get started!</p>

<p>Files in HDFS are split into <em>blocks</em>. When getting a file from HDFS,
the first thing we need to do is to ask the namenode where the blocks
are stored.</p>

<p>With the help of a lot of snakebite source diving, I write a small
Python function to do this called <code>find_blocks</code>. You can see it in a
tiny Python module I made called
<a href="https://github.com/jvns/hadoop_fun/blob/master/hdfs_fun.py">hdfs_fun.py</a>.
To get it to work, you&rsquo;ll need a Hadoop cluster and snakebite.</p>

<pre>
>>> cl = hdfs_fun.create_client()
>>> hdfs_fun.find_blocks(cl, '/wikipedia')
[snakebite.protobuf.hdfs_pb2.LocatedBlockProto at 0xe33a910,
 snakebite.protobuf.hdfs_pb2.LocatedBlockProto at 0xe33ab40
</pre>

<p>One of the first things I did was use <code>strace</code> to find out what data actually gets sent over the wire when I call this function. Here&rsquo;s a snippet: (<a href="https://gist.github.com/jvns/bc054ea0f38b5054fd3a">the whole thing</a>)</p>

<p>Part of the request: asking for the block locations for the
<code>/wikipedia</code> file.
<pre>
sendto(7,
&ldquo;\n\21getBlockLocations\22.org.apache.hadoop.hdfs.protocol.ClientProtocol\30\1&rdquo;,
69, 0, NULL, 0) = 69
sendto(7, &ldquo;\n\n/wikipedia\20\0\30\337\260\240]&ldquo;, 19, 0, NULL, 0) = 19
</pre></p>

<p>Part of the response: (I&rsquo;ve removed most of it to point out some of
the important parts)
<pre>
recvfrom(7,
&ldquo;&hellip;.BP-1019336183-10.165.43.39-1400088409498&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;..
10.147.177.170-9200-1400088495802&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;
BP-1019336183-10.165.43.39-1400088409498&hellip;&hellip;&hellip;&hellip;.10.147.177.170-9200-1400088495802
\360G(\216G0\361G8\0\20\200\240\201\213\275\f\30\200\340\376]
\200\300\202\255\274\f(\200\340\376]0\212\306\273\205\340(8\1B\r/default-rackP\0
\0*\10\n\0\22\0\32\0\&rdquo;\0\30\0\&rdquo;\355&rdquo;, 731, 0, NULL, NULL) = 731
</pre></p>

<p>Back in our Python console, we can see what some of these numbers mean:</p>

<pre>
>>> blocks[0].b.poolId
u'BP-1019336183-10.165.43.39-1400088409498'
>>> blocks[0].b.numBytes
134217728L
>>> blocks[0].locs[0].id.ipAddr
u'10.147.177.170'
>>> blocks[0].locs[0].id.xferPort
9200
>>> blocks[1].b.poolId
u'BP-1019336183-10.165.43.39-1400088409498'
>>> blocks[1].b.numBytes
61347935L
</pre>

<p>So we have two blocks! The two <code>numBytes</code> add up to the total size of
the file! Cool! They both have the same <code>poolId</code>, and it also turns
out that they have the same IP address and port</p>

<h3 id="reading-a-block">Reading a block</h3>

<p>Let&rsquo;s try to read the data from a block! (you can see the <code>read_block</code>
function here in
<a href="https://github.com/jvns/hadoop_fun/blob/master/hdfs_fun.py">hdfs_fun.py</a></p>

<pre>
>>> block = blocks[0]
>>> gen = hdfs_fun.read_block(block) # returns a generator
>>> load = gen.next()
</pre>

<p>If I look at <code>strace</code>, it starts with:
<pre>
connect(8, {sa_family=AF_INET, sin_port=htons(9200),
    sin_addr=inet_addr(&ldquo;10.147.177.170&rdquo;)}, 16) = 0
sendto(8,
    &ldquo;\nB\n5\n3\n(BP-1019336183-10.165.43.39-1400088409498\20\211\200\200\200\4\30\361\7\22\tsnakebite\20\0\30\200\200\200@&ldquo;,
    75, 0, NULL, 0) = 75
</pre></p>

<p><em>Awesome</em>. We can see easily that it&rsquo;s connecting to the block&rsquo;s data
 node (<code>10.147.177.170</code> on port <code>9200</code>, and asking for something with
 id <code>BP-1019336183-10.165.43.39-1400088409498</code>). Then the data node
 starts sending back data!!!</p>

<pre>
recvfrom(8, "ot, it's a painting. Thomas Graeme apparently lived in
the mid-18th century, according to the [[Graeme Park]] article. The
rationale also says that this image is &quot;used on the biography
page about him by USHistory.org of Graeme Park.&quot; I cannot quite
figure out what this means, but I am guessing that it means the
uploader took this image from a page hosted on USHistory.org. A
painting of a man who lived in the mid-18th century is likely to be
the public domain, as claimed, but we have no good source", 512, 0,
NULL, NULL) = 512
</pre>

<p>AMAZING. We have conquered HDFS.</p>

<p>That&rsquo;s all for this blog post! We&rsquo;ll see if I do more later today.</p>
</div>
<footer>
<div class="sharing">
<a href="http://twitter.com/share" class="twitter-share-button" data-url="https://jvns.ca/blog/2014/05/15/diving-into-hdfs/" data-via="b0rk" data-counturl="https://jvns.ca/blog/2014/05/15/diving-into-hdfs/">Tweet</a>
</div>
<p class="meta">
   
    <a class="basic-alignment left" href="https://jvns.ca/blog/2014/05/28/anonymous-talk-submission-equals-amazing/" title="Previous Post: Anonymous talk review is amazing.">Anonymous talk review is amazing.</a>
  
   
    <a class="basic-alignment right" href="https://jvns.ca/blog/2014/05/13/profiling-with-perf/" title="Previous Post: I can spy on my CPU cycles with perf!">I can spy on my CPU cycles with perf!</a>
  
</p>
</footer>
</article>
</div>

</div>
</div>
<nav role="navigation" class="footer-nav"> <a href="/">Archives</a>
</nav>
<footer role="contentinfo"><span class="credit">&copy; 2016 Polina Soshnin.
</footer>
</div>
</body>
</html>


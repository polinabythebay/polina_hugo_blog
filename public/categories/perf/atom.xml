<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Julia Evans]]></title>
  <link href="http://jvns.ca/atom.xml" rel="self"/>
  <link href="https://jvns.ca/categories/perf/atom/index.xml"/>
  <updated>0001-01-01T00:00:00+00:00</updated>
  <id>http://jvns.ca</id>
  <author>
    <name><![CDATA[Julia Evans]]></name>
  </author>
  <generator uri="http://gohugo.io/">Hugo</generator>

  
  <entry>
    <title type="html"><![CDATA[How does perf work? (in which we read the Linux kernel source)]]></title>
    <link href="https://jvns.ca/blog/2016/03/12/how-does-perf-work-and-some-questions/"/>
    <updated>2016-03-12T11:09:40+00:00</updated>
    <id>https://jvns.ca/blog/2016/03/12/how-does-perf-work-and-some-questions/</id>
    <content type="html"><![CDATA[

<p>perf is a profiling tool for Linux, that I&rsquo;ve written about <a href="/blog/categories/perf">a few times</a> on this blog before. I was interviewed on <a href="http://embedded.fm/episodes/141">a podcast</a> recently where the host asked me &ldquo;so, julia, tell me how perf works!&rdquo; and I gave a sort of unsatisfying answer &ldquo;you know, sampling?&rdquo;.</p>

<p>So it turns out I don&rsquo;t really know how perf works. And I like knowing how stuff works. Last week I read some of the <a href="http://man7.org/linux/man-pages/man2/perf_event_open.2.html">man page for <code>perf_event_open</code></a>, the system call that perf uses. It&rsquo;s 10,000 words but pretty helpful! I&rsquo;m still quite confused about perf, so I&rsquo;m going to tell you, fair reader, what I know, and then maybe you can help me out with my questions.</p>

<p>There is not a lot of documentation for perf. The best resource I know is on <a href="http://www.brendangregg.com/perf.html">Brendan Gregg&rsquo;s site</a>, but it does not answer all the questions I have! To answer some of these questions, we&rsquo;re going to read the Linux kernel source code. Because it&rsquo;s Saturday night.</p>

<h3 id="hardware-counters">Hardware counters</h3>

<p>So, let&rsquo;s imagine you want to know exactly how many CPU instructions happen when you run <code>ls</code>. It turns out that your CPU stores information about this kind of thing! And perf can tell you. Here&rsquo;s what the answer looks like, from <code>perf stat</code>.</p>

<pre><code>$ sudo perf stat ls
         1,482,453 instructions              #    0.48  insns per cycle        

</code></pre>

<p>But how does that <em>work</em>? Well, the <a href="https://en.wikipedia.org/wiki/Hardware_performance_counter">Wikipedia page on hardware performance counters</a> mentions</p>

<blockquote>
<p>One of the first processors to implement such counter and an associated
instruction <code>RDPMC</code> to access it was the Intel Pentium, but they were not
documented until Terje Mathisen wrote an article about reverse engineering
them in Byte July 1994: [1]</p>
</blockquote>

<p>We can use <a href="https://livegrep.com/search/linux">http://livegrep.com</a> to search the Linux kernel for the <code>rdpmc</code> instruction. Here&rsquo;s it being used in a cryptic <a href="https://github.com/torvalds/linux/blob/v4.3/arch/x86/include/asm/msr.h#L158-L164">header file called msr.h</a></p>

<pre><code>static inline unsigned long long native_read_pmc(int counter)
{
    DECLARE_ARGS(val, low, high);

    asm volatile(&quot;rdpmc&quot; : EAX_EDX_RET(val, low, high) : &quot;c&quot; (counter));
    return EAX_EDX_VAL(val, low, high);
}
</code></pre>

<p>This is AWESOME. Maybe this is how Linux reads hardware counters and gives them back to us in <code>perf stat</code>!! Further grepping for uses of <code>native_read_pmc</code> reveals that we read hardware counters via <code>rdpmcl</code> in <a href="https://github.com/torvalds/linux/blob/v4.3/arch/x86/kernel/cpu/perf_event.c#L84">x86/kernel/cpu/perf_event.c</a>.</p>

<p>This code is a little impenetrable to me, but here&rsquo;s a hypothesis for how this could work. Let&rsquo;s say we&rsquo;re running <code>ls</code>. This code might get scheduled on and off the CPU a few times.</p>

<p>So! Here&rsquo;s what I think this looks like.</p>

<pre><code>kernel: ok let's run ls for a while
kernel: CPU! Start counting CPU instructions!
CPU: &lt;complies silently&gt;
kernel: &lt;runs ls&gt;
ls: yayyyyyyyyyy
kernel: &lt;stops running ls&gt;
kernel: CPU! How many instructions was that! (`rdpmc`)
CPU: 10,200!
kernel: &lt;increments counter by 10,200&gt;
</code></pre>

<p>One important outcome of this, if I understand correctly is &ndash; hardware counters are exact counters, and they&rsquo;re low enough overhead that the kernel can just always run <code>rdpmc</code> every time it&rsquo;s done running a piece of code. There&rsquo;s no sampling or approximations involved.</p>

<h3 id="sampling-software-events">Sampling software events</h3>

<p>The core of perf events looks like it&rsquo;s in <a href="https://github.com/torvalds/linux/blob/v4.3/kernel/events/core.c">kernel/events/core.c</a>. This file includes the definition of the <a href="https://github.com/torvalds/linux/blob/v4.3/kernel/events/core.c#L8107"><code>perf_event_open</code></a> system call, on line 8107. Files with 10,000 lines of C code are not my specialty, but I&rsquo;m going to try to make something of this.</p>

<p>My goal: understand how perf does sampling of CPU events. For the sake of argument, let&rsquo;s pretend we only wanted to save the state of the CPU&rsquo;s registers every time we sample.</p>

<p>We know from the <a href="http://man7.org/linux/man-pages/man2/perf_event_open.2.html"><code>perf_event_open</code> man page</a> that perf writes out events to userspace (&ldquo;hi! I am in julia&rsquo;s awesome function right now!&rdquo;). It writes events to a mmap&rsquo;d <em>ring buffer</em>. Which is some data structure in memory. Okay.</p>

<p>Further inspection of this 10,000 line <code>core.c</code> file reveals that the code outputs data to userspace in the <code>perf_event_update_userpage</code> function.</p>

<p>So, let&rsquo;s find the code that copies all the x86 registers into userspace! It turns out it&rsquo;s not too hard to find &ndash; it&rsquo;s in this file called <a href="https://github.com/torvalds/linux/blob/v4.3/arch/x86/kernel/perf_regs.c#L114-L118">perf_regs.c</a>. There are like 15 registers to copy! Neat.</p>

<p>In this case it makes sense that we sample &ndash; we definitely couldn&rsquo;t save all the registers every instruction. That would be way too much work!</p>

<p>So now I can see a little tiny bit of the code that perf uses to do sampling. This isn&rsquo;t terribly enlightening, but it does make me feel better.</p>

<h3 id="questions">Questions</h3>

<ul>
<li>when does perf do its sampling? is it when the process gets scheduled onto the CPU? how is the sampling triggered? I am completely confused about this.</li>
<li>what is the relationship between perf and kprobes? if I just want to sample the registers / address of the instruction pointer from <code>ls</code>&rsquo;s execution, does that have anything to do with kprobes? with ftrace? I think it doesn&rsquo;t, and that I only need kprobes if I want to instrument a kernel function (like a system call), but I&rsquo;m not sure.</li>
<li>are kprobes and ftrace the same kernel system? I feel like they are but I am confused.</li>
</ul>

<h3 id="reading-kernel-code-not-totally-impossible">reading kernel code: not totally impossible</h3>

<p>I probably skimmed like 4000 lines of Linux kernel code (the perf parts!) to write this post, in 3 hours. There are definitely at least 20,000 lines of code related to perf. Maybe 100,000? I do not have the Linux source on my computer &ndash; I used livegrep and github to look at it.</p>

<p>I only understood probably 10% of what I looked at, but I still learned some things about how perf works internally! This is neat.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[perf top: an awesome way to spy on CPU usage]]></title>
    <link href="https://jvns.ca/blog/2016/02/24/perf-top-my-new-best-friend/"/>
    <updated>2016-02-24T22:49:44+00:00</updated>
    <id>https://jvns.ca/blog/2016/02/24/perf-top-my-new-best-friend/</id>
    <content type="html"><![CDATA[

<p>If you read this blog, you might know that I <a href="http://jvns.ca/blog/2015/04/14/strace-zine/">love strace, so much that I wrote a zine about it</a>. But strace has not ever been able to solve all my problems &ndash; it only tells me about system calls, it can slow down my code up to 50x. Not ideal!</p>

<p>So, enter <code>perf</code>. We <a href="http://jvns.ca/blog/2014/05/13/profiling-with-perf/">learned about perf</a> a couple of years ago, when we found out that it can tell you about how many CPU cycles your program is using. That was cool, but ultimately not that useful to me right now (I&rsquo;m trying to make Ruby programs fast!).</p>

<p>But! A couple of months ago I learned about <code>perf top</code>, which tells you which functions are in use on your computer right now (the same way <code>top</code> does for programs). I have three stories for you about how perf top is the best and has helped me solve problems.</p>

<p>First, I&rsquo;m going to show you what <code>sudo perf top</code> gives me on my computer right now:</p>

<pre><code>$ sudo perf top
26.63%  chrome                               [.] 0x0000000000fe202b
 2.20%  perf                                 [.] 0x00000000000523fd
 1.12%  [kernel]                             [k] _raw_spin_lock_irqsave
 1.10%  MusicManager_x86_64.nexe             [.] sqlite3VdbeExec
 0.98%  [kernel]                             [k] fget_light
 0.91%  perf-10709.map                       [.] 0x00001db39d555f0d
 0.89%  [kernel]                             [k] aes_decrypt
 0.88%  [kernel]                             [k] sock_poll
 0.82%  [kernel]                             [k] aes_encrypt
 0.78%  [kernel]                             [k] __schedule
 0.76%  .com.google.Chrome.Bc2ixX            [.] 0x000000000feda002
</code></pre>

<p>You can see that some mystery function in Chrome is responsible for 26% of CPU usage, perf itself has some overhead, <code>MusicManager_x86_64</code> is using sqlite (what? why?), and there are various things going on inside my kernel. Neat.</p>

<p>Now, let&rsquo;s see some real examples of perf in action!</p>

<h3 id="the-case-of-the-sad-node-program">the case of the sad Node program</h3>

<p>I needed to debug a node program recently. It was super slow, and spending a ton of time on the CPU. I had no idea why.</p>

<p>Since my new hobby is to run <code>perf top</code> any time I have a question about CPU usage, I ran perf! I don&rsquo;t have the real results here, but I basically saw something like this:</p>

<pre><code>node                 [.] v8::internal::StackFrame::GetCallerState(v8::internal::StackFrame::State*) const
node                 [.] v8::internal::SemiSpace::Swap(v8::internal::SemiSpace*, v8::internal::SemiSpace*)
node                 [.] v8::internal::ScavengeVisitor::VisitPointers(v8::internal::Object**, v8::internal::Object**)
node                 [.] v8::internal::GCTracer::Start(v8::internal::GarbageCollector, char const*, char const*)
node                 [.] v8::internal::Heap::ClearJSFunctionResultCaches()
node                 [.] v8::internal::InnerPointerToCodeCache::GetCacheEntry(unsigned char*)
node                 [.] v8::internal::Runtime_AllocateInTargetSpace(int, v8::internal::Object**,
</code></pre>

<p>I didn&rsquo;t know what all of it meant, but it seemed clear that the program was spending most of its time doing garbage collection. No good! We didn&rsquo;t manage to figure out <em>why</em> it was garbage collecting, but it was awesome to be able to quickly triage what was going on.</p>

<h3 id="the-case-of-the-swapping-computer">the case of the swapping computer</h3>

<p>Today at work, I had a program that was slow. Surprise! A lot of stories these days start this way. The computer was using a lot of CPU, and I wanted to know why.</p>

<p>Here&rsquo;s what <code>perf top</code> had to say about that:</p>

<p><img src="/images/swap-perf.png"></p>

<p>This is a totally different story from our node story &ndash; in this case, the <strong>linux kernel</strong> is using all our CPU. What?! Why?</p>

<p>It turns out that the computer was swapping its memory to disk, and that the swap partition was encrypted. So every time it saved memory to disk or read it back, it needed to encrypt and decrypt all that memory. The CPU load on that machine was like 15. It was having a bad day.</p>

<p>We fixed the memory usage on the machine, and everything was all better ❤.</p>

<h3 id="the-case-of-the-http-request">the case of the HTTP request</h3>

<p>Our last case is a Python mystery! This one is a fake mystery that I made up, but it illustrates a real possible slow program.</p>

<p>So! I ran a Python program to download several files, and it used 100% of my CPU for several seconds. What was it doing? Let&rsquo;s ask perf top!!</p>

<pre><code>24.92%  libcrypto.so.1.0.0  [.] 0x00000000001264e4
 8.88%  libcrypto.so.1.0.0  [.] EVP_DecodeUpdate
 6.23%  libc-2.15.so        [.] malloc
 5.62%  python              [.] 0x00000000000e9b5d
 4.48%  libc-2.15.so        [.] malloc_consolidate.part.3
 3.25%  python              [.] PyEval_EvalFrameEx
 2.77%  libcrypto.so.1.0.0  [.] EVP_DecodeBlock
 2.63%  libcrypto.so.1.0.0  [.] ASN1_item_ex_d2i
 2.07%  libcrypto.so.1.0.0  [.] X509_NAME_cmp
 1.62%  libc-2.15.so        [.] msort_with_tmp.part.0
 1.62%  libcrypto.so.1.0.0  [.] ASN1_item_ex_i2d
</code></pre>

<p>It seems to be doing&hellip; a lot of crypto? Why? Here&rsquo;s the program:</p>

<pre><code>import grequests

rs = (grequests.get('https://news.ycombinator.com') for i in xrange(1000))

grequests.map(rs)
</code></pre>

<p>It turns out that opening a HTTPS connection is pretty slow! You need to spend a bunch of time in crypto functions in order to be secure. And perf tells us immediately that that&rsquo;s what&rsquo;s going on! Awesome.</p>

<h3 id="but-there-s-more">But there&rsquo;s more</h3>

<p>So I&rsquo;ve gone through a few examples of how perf can sometimes help triage what a program is spending its CPU time on, even if the program is written in node or Python or something.</p>

<p>There&rsquo;s a limitation here that you may have noticed &ndash; perf will only tell us about C functions (like <code>EVP_DecodeUpdate</code> or something).</p>

<p>So you may be thinking &ndash; &ldquo;my node program isn&rsquo;t garbage collecting! It&rsquo;s spending its time in some Javascript function! perf will not help me at all!&rdquo; And what if I&rsquo;m using Java, Julia? This will not help me with Java!</p>

<p>perf is even more magical than you might expect, though! You can <strong>tell perf about your Java and node functions</strong>. This blew my mind when I learned it and is continuing to blow my mind. If you want to make perf amazing for Java, read this blog post <a href="http://techblog.netflix.com/2015/07/java-in-flames.html">Java in flames</a></p>

<p><a href="http://www.brendangregg.com/perf.html">Brendan Gregg&rsquo;s page on perf</a> has more about perf and how great it is and how to use it to help debug your node.js programs.</p>

<h3 id="a-toolbox-of-delightful-tools">a toolbox of delightful tools</h3>

<p>I&rsquo;m slowly building a toolbox of easy-to-use tools that will help me understand what my programs are doing. There are a few things that are farther down the list (ftrace and systemtap are still very confusing to me and I do not know how to use them.)</p>

<p>But <code>perf top</code> is so simple (just one command!), and so straightforward, and I think it deserves to go in your toolbox. It works on Linux. Try it out! See what happens! Run it everywhere! It&rsquo;s safe to run in production.</p>

<p><code>sudo perf top</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Seeing system calls with perf instead of strace]]></title>
    <link href="https://jvns.ca/blog/2015/03/30/seeing-system-calls-with-perf-instead-of-strace/"/>
    <updated>2015-03-30T21:42:36+00:00</updated>
    <id>https://jvns.ca/blog/2015/03/30/seeing-system-calls-with-perf-instead-of-strace/</id>
    <content type="html"><![CDATA[

<p>I&rsquo;m at a local hackerspace this evening, and I decided to get <code>perf</code>
working on my computer again. You all know by now that I&rsquo;m pretty into
strace, but &ndash; strace is not always a good choice! If your program runs
too many system calls, strace will slow it down. A lot.</p>

<p>Let&rsquo;s try it and see:</p>

<pre><code>$ time du -sh ~/work
0.04 seconds
$ time strace -o out du -sh ~/work
2.66 seconds
</code></pre>

<p>That&rsquo;s 65 times slower! This is because <code>du</code> needed to use 260,000
system calls, which is uh a lot. If you strace a program with less
system calls it won&rsquo;t be that big of a deal. But what if we still want
to know what <code>du</code> is doing, and <code>du</code> is actually a Really Important
Program like a database or something?</p>

<h3 id="we-re-going-to-use-perf-d-d">WE&rsquo;RE GOING TO USE PERF =D =D.</h3>

<p>I&rsquo;ve been eyeing Brendan Gregg&rsquo;s
<a href="http://www.brendangregg.com/perf.html">page on perf</a>
and the <a href="https://perf.wiki.kernel.org/index.php/Tutorial">kernel.org tutorial</a>
for almost a year now, and we learned in May last year that
<a href="http://jvns.ca/blog/2014/05/13/profiling-with-perf/">perf lets you count CPU cycles</a>, which is
cool! But perf is capable of way more stuff.</p>

<p>Here&rsquo;s how we record what system calls <code>du</code> is using:</p>

<pre><code>sudo perf record -e 'syscalls:sys_enter_*' du -sh ~/work
</code></pre>

<p>This finishes right away, except that perf takes a little extra time to
write its recorded data to desk. Then we can see the system calls with
<code>sudo perf script</code>, which shows us something like this:</p>

<pre><code>du 25156 [003] 142769.540801: syscalls:sys_enter_newfstatat:
       dfd: 0x00000006, filename: 0x021b0b58, statbuf: 0x021b0ac8, flag: 0x0
du 25156 [003] 142769.540802: syscalls:sys_enter_close:
       fd: 0x00000006
du 25156 [003] 142769.540804: syscalls:sys_enter_newfstatat: 
       dfd: 0x00000005, filename: 0x021b4708, statbuf: 0x021b4678, flag: 0x0
</code></pre>

<p>This is showing us system calls! You can see the file descriptors &ndash;
<code>fd: 0x00000006</code>. But it doesn&rsquo;t give us the filename, just&hellip; the
address of the filename? I don&rsquo;t know how to get the actual filename out
and that makes me sad.</p>

<p>It&rsquo;s called <code>perf script</code> because you can write scripts with the output
(like this <a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">flamegraph script</a>!).
Like maybe you could pretty it up and have a script that&rsquo;s like strace
but doesn&rsquo;t slow your program down so much. Apparently <code>perf script -g python</code>
will automatically generate boilerplate for a perf script in Python for
me! But it doesn&rsquo;t work because I need to recompile perf. So we&rsquo;ll see
about that :)</p>

<p>That&rsquo;s all I have to say for now! Mostly I&rsquo;m writing this up in the
hopes that someone will either a) tell me how to get perf to give me the
actual filename or b) tell me why it&rsquo;s unreasonable to expect perf to do
that.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I can spy on my CPU cycles with perf!]]></title>
    <link href="https://jvns.ca/blog/2014/05/13/profiling-with-perf/"/>
    <updated>2014-05-13T20:47:49+00:00</updated>
    <id>https://jvns.ca/blog/2014/05/13/profiling-with-perf/</id>
    <content type="html"><![CDATA[<p>Yesterday I talked about using <code>perf</code> to profile assembly
instructions. Today I learned how to make flame graphs with <code>perf</code>
today and it is THE BEST. I found this because
<a href="https://twitter.com/graydon_moz">Graydon Hoare</a> pointed me to Brendan
Gregg&rsquo;s <em>excellent</em>
<a href="http://www.brendangregg.com/perf.html">page on how to use perf</a>.</p>

<p>Wait up! What&rsquo;s <code>perf</code>? I&rsquo;ve talked about <code>strace</code> a lot before (in
<a href="http://jvns.ca/blog/2014/04/20/debug-your-programs-like-theyre-closed-source/">Debug your programs like they&rsquo;re closed source</a>).
<code>strace</code> lets you see which system calls a program is calling. But
what if you wanted to know</p>

<ul>
<li>how many CPU instructions it ran?</li>
<li>How many L1 cache misses there were?</li>
<li>profiling information for each assembly instruction?</li>
</ul>

<p><code>strace</code> only does system calls, and none of those things are system
calls. So it can&rsquo;t tell you any of those things!</p>

<p></p>

<p><code>perf</code> is a Linux tool that can tell you all of these things, and
more! Let&rsquo;s run a quick example on the
<a href="http://jvns.ca/blog/2014/05/12/computers-are-fast/">bytesum program from yesterday</a>.</p>

<pre>
bork@kiwi ~/w/howcomputer> perf stat ./bytesum_mmap *.mp4
 Performance counter stats for './bytesum_mmap The Newsroom S01E04.mp4':

        158.141639 task-clock                #    0.994 CPUs utilized          
                22 context-switches          #    0.139 K/sec                  
                 9 CPU-migrations            #    0.057 K/sec                  
               133 page-faults               #    0.841 K/sec                  
       438,662,273 cycles                    #    2.774 GHz                     [82.43%]
       269,916,782 stalled-cycles-frontend   #   61.53% frontend cycles idle    [82.38%]
       131,557,379 stalled-cycles-backend    #   29.99% backend  cycles idle    [66.66%]
       681,518,403 instructions              #    1.55  insns per cycle        
                                             #    0.40  stalled cycles per insn [84.88%]
       130,568,804 branches                  #  825.645 M/sec                   [84.85%]
            20,756 branch-misses             #    0.02% of all branches         [83.68%]

       0.159154389 seconds time elapsed
</pre>

<p>This is super neat information, and there&rsquo;s a lot more (see <code>perf
list</code>). But we can do even more fun things!</p>

<h3 id="flame-graphs-with-perf">Flame graphs with perf</h3>

<p>I wanted to profile my <code>bytesum</code> program. But how do you even profile
C programs? Here&rsquo;s a way to do it with <code>perf</code>:</p>

<pre>
sudo perf record -g ./bytesum_mmap *.mp4
sudo perf script | stackcollapse-perf.pl | flamegraph.pl > flamegraph.svg
</pre>

<p>Here&rsquo;s the SVG this gave me:</p>

<p><img src="/images/flamegraph.svg"></p>

<p>This is AMAZING. But what does it mean? Basically <code>perf</code> periodically
interrupts the program and finds out where in the stack it is. The
width of each part of the stack in the graph above is the proportion
of samples that happened there. (so about 30% of the execution time
was spend in <code>main</code>). I don&rsquo;t know what the colour means here.</p>

<p>We can see that there are 3 big parts &ndash; there&rsquo;s the <code>mmap</code> call (on
the left), the main program execution (in the middle), and the
<code>sys_exit</code> part on the right. Apparently stopping my program takes a
long time! Neat!</p>

<p>But there&rsquo;s more!</p>

<h3 id="is-it-really-l1-cache-misses-we-can-find-out">Is it really L1 cache misses? We can find out!</h3>

<p>So yesterday I made a program with really bad memory access patterns
(<a href="https://github.com/jvns/howcomputer/blob/master/bytesum_stride.c">bytesum_stride.c</a>),
and I conjectured that it was way slower because it was causing way
too many L1 cache misses.</p>

<p>But with <code>perf</code>, we can check if that&rsquo;s actually true! Here are the
results (reformatted a bit to be more compact):</p>

<pre>
bork@kiwi ~/w/howcomputer> perf stat -e L1-dcache-misses,L1-dcache-loads ./bytesum_mmap *.mp4
        17,175,214 L1-dcache-misses #   11.48% of all L1-dcache hits  
       149,568,438 L1-dcache-loads
bork@kiwi ~/w/howcomputer> perf stat -e L1-dcache-misses,L1-dcache-loads ./bytesum_stride *.mp4 1000
     1,031,902,483 L1-dcache-misses #  193.16% of all L1-dcache hits  
       534,219,219 L1-dcache-loads
</pre>

<p>So, uh, that&rsquo;s really bad. We now have <strong>60 times more</strong> L1 cache
misses, and also 3 times more hits.</p>

<h3 id="other-amazing-things">Other amazing things</h3>

<ul>
<li>Go to
<a href="http://www.brendangregg.com/perf.html">Brendan Gregg&rsquo;s perf page and read the whole thing</a>.
Also possibly everything he&rsquo;s ever written. His recent post on
<a href="http://www.brendangregg.com/blog/2014-05-11/strace-wow-much-syscall.html">strace</a>
is great too.</li>
<li>The <a href="https://perf.wiki.kernel.org/index.php/Tutorial">perf tutorial</a>
is pretty long, but I found it somewhat helpful.</li>
<li><a href="https://github.com/brendangregg/FlameGraph">FlameGraph!</a></li>
<li>I spent a little bit of time running cachegrind with
<code>valgrind --tool=cachegrind ./bytesum_mmap my_file</code>
which can give you possibly even more information about CPU caches
than <code>perf</code> can. Still haven&rsquo;t totally wrapped my head around this.</li>
</ul>

<p>There are still so many things I don&rsquo;t understand at all!</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Computers are *fast*!]]></title>
    <link href="https://jvns.ca/blog/2014/05/12/computers-are-fast/"/>
    <updated>2014-05-12T21:31:59+00:00</updated>
    <id>https://jvns.ca/blog/2014/05/12/computers-are-fast/</id>
    <content type="html"><![CDATA[<p>So I have a computer. My computer contains hardware (like a CPU! RAM!
L1/L2 caches!) But I don&rsquo;t understand very well how fast that hardware
is, what tools I have to profile it, and how much of the time that my
programs are running is split between RAM/the hard disk/the CPU.</p>

<p>So today I paired with
<a href="https://twitter.com/SashaLaundy">Sasha Laundy</a>, and we ran Serious
Investigations into how fast my computer can process a 1GB file.</p>

<p><strong>The objects:</strong></p>

<ul>
<li>An episode of The Newsroom (1GB)</li>
<li>A task: add up all the bytes (mod 256)</li>
</ul>

<p>This was basically the easiest task that I could think of that
involved processing the entire file (so nothing gets optimized out by
the compiler).</p>

<p></p>

<h3 id="step-1-write-a-program-to-add-up-all-the-bytes">Step 1: Write a program to add up all the bytes</h3>

<p>I wrote a small C program to add up all the bytes in a file. It&rsquo;s
called
<a href="https://github.com/jvns/howcomputer/blob/master/bytesum.c">bytesum.c</a>.
It reads the file in chunks of 64k, and then adds up all the bytes
into a char.</p>

<p>This runs pretty fast! I compiled it with <code>gcc -Ofast</code> (to make it
FASTER!) and it added up all the bytes in</p>

<ul>
<li>2.5 seconds (the first time I ran the program)</li>
<li>0.6 seconds (the second time I ran the program, because it&rsquo;s already
loaded into RAM)</li>
</ul>

<p>I take this to mean that it takes 2s to read the file into memory (I
have a SSD in my computer, so 500MB/s makes sense), and then 0.6s to
do the actual adding-up-of-the bytes. Awesome! We now know that I can
read from my hard drive at 500MB/s.</p>

<h3 id="step-2-try-to-use-mmap-to-make-it-faster">Step 2: try to use <code>mmap</code> to make it faster</h3>

<p>This is a pretty boring step. We made it use <code>mmap</code> instead (see
<a href="https://github.com/jvns/howcomputer/blob/master/bytesum_mmap.c">bytesum_mmap.c</a>),
in the hopes that it would make it faster. It took exactly the same
amount of time. NEXT.</p>

<h3 id="step-3-use-vector-intrinsics">Step 3: use vector intrinsics!!!</h3>

<p>Then I went and talked to <a href="http://jamesporter.me/">James Porter</a>, and
he told me that CPUs have special instructions for doing multiple
additions at once, and that I could maybe use them to optimize my
program! So I googled &ldquo;vector intrinsics&rdquo;, copied some code from Stack
Overflow, and ended up with a new version:
<a href="https://github.com/jvns/howcomputer/blob/master/bytesum_intrinsics.c">bytesum_intrinsics.c</a>.
I timed it, and it took <strong>0.25 seconds</strong>!!!</p>

<p>So our program now runs <strong>twice as fast</strong>, and we know a whole bunch
of new words (SSE! SIMD! vector intrinsics!)</p>

<h3 id="step-4-make-it-slow">Step 4: Make it slow.</h3>

<p>Now that we&rsquo;ve written a super fast program, I wanted to understand
the CPU caches better. What if we engineered a whole bunch of cache
misses? I wrote a new version of <code>bytesum_mmap.c</code> that added up all
the bytes in an irregular way &ndash; instead of going through all the
bytes in order, it would skip from byte 1 to 2001 to 3001 to 4001 and
then loop around and access 2, 2002, 3002, &hellip;, 100002. As you might
imagine, this isn&rsquo;t very efficient.</p>

<p>You can see the code for this in
<a href="https://github.com/jvns/howcomputer/blob/master/bytesum_stride.c">bytesum_stride.c</a>.
I ran it with <code>./bytesum_stride *.mp4 60000</code>, and it took about 20
seconds. So we&rsquo;ve learned that <strong>cache misses can make your code 40
times slower</strong>.</p>

<h3 id="step-5-where-do-the-0-25-seconds-come-from">Step 5: where do the 0.25 seconds come from???</h3>

<p>I still didn&rsquo;t totally understand exactly how my super fast vector
intrinsic program&rsquo;s performance broke down, though: how much of that
0.25 seconds was spent doing memory accesses, and how much in
numerical computation? James suggested using
<a href="http://marss86.org/~marss86/index.php/Home">Marss</a> which will
apparently give you unlimited amounts of information, but I spent a
few minutes trying to get it to work and failed.</p>

<p>So instead I used <code>perf</code>, which is a <em>totally magical</em> performance
measurement tool for Linux. I needed to upgrade my kernel first, which
was a bit nervewracking. But I did it! And it was beautiful. There are
colours, and we got it to annotate the assembly code with performance
statistics. Here&rsquo;s what I ran to do it:</p>

<pre>
perf record ./bytesum_intrinsics The\ Newsroom\ S01E04.mp4
perf annotate --no-source
</pre>

<p>And here&rsquo;s the result:</p>

<p><img src="/images/perf.png"></p>

<p>The <code>movdqa</code> instructions have to do with accessing memory, and it
spends 32% of its time on those instructions. So I <em>think</em> that means
that it spends 32% of its time accessing RAM, and the other 68% of its
time doing calculations. Super neat!</p>

<p>There are still a lot of things I don&rsquo;t understand here &ndash; are my
conclusions about this program correct? Are there further things I
could be doing to optimize this?</p>

<p>I&rsquo;m also kind of amazed by how fast C is. I&rsquo;m used to writing in
dynamic programming languages, which definitely do not process 1GB
files in 0.25 seconds. Fun!</p>]]></content>
  </entry>
  
</feed>